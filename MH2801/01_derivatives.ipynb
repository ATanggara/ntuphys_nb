{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# 1. Derivatives\n",
    "\n",
    "<a name=\"derivative_definition\"></a>\n",
    "The **derivative** of a function $f$ is another function, $f'$, defined as follows:\n",
    "\n",
    "$$f'(x) \\;\\equiv\\; \\frac{df}{dx} \\;\\equiv\\; \\lim_{\\delta x \\rightarrow 0} \\, \\frac{f(x + \\delta x) - f(x)}{\\delta x}.$$\n",
    "\n",
    "This kind of expression is called a **limit expression** because it involves a limit (in this case, the limit where $\\delta x$ goes to zero).\n",
    "\n",
    "If the value of the above limit expression is unique and well-defined within some domain of $x$, we say that the derivative \"exists\" in that domain.  We also say that $f(x)$ is **differentiable** in that domain.  It can be shown that a differentiable function is automatically [continuous](00_mathfunctions.ipynb#continuity). ([Try proving it](#exercises)!) If the derivative exists, we can define the second-order derivative of $f$ as the derivative of $f'$. Third- and higher-order derivatives are defined similarly.\n",
    "\n",
    "Graphically, the derivative represents the slope of the graph of $f(x)$, while the second derivative represents the curvature.  The interactive graph below shows the example of the function $f(x) = x^2 + 1$, illustrating how its derivative, $f'(x) = 2x$, varies with $x$. (Note also that the curve is upward-curving, corresponding to the fact that the second derivative, $f''(x) = 2$, is positive.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22c0feac3f664ae6b45f1e2789ec5dd9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Run this code cell to generate an interactive graph illustrate the derivative concept.\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact, FloatSlider\n",
    "from scipy import linspace\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_derivative(x0):\n",
    "    xmin, xmax, ymin, ymax = 0., 4.5, 0., 18.\n",
    "    x = linspace(xmin, xmax, 100)\n",
    "    y = x*x+1\n",
    "\n",
    "    ## Plot y=x^2+1, and a triangle at x = x0, with base length 1 and height dy/dx = 2x\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(x, y)\n",
    "    x1, y0, dydx = x0+1, x0*x0+1, 2*x0\n",
    "    plt.plot([x0, x1, x1, x0], [y0, y0, y0+dydx, y0], color='red')\n",
    "    plt.plot([x0, x0], [0, y0], '--', color='grey')\n",
    "    \n",
    "    ## Axes, text labels, etc.\n",
    "    plt.text(x1+0.05, y0+0.5*dydx, \"f ' (x0) = {0:.2f}\".format(dydx))\n",
    "    plt.text(x0+0.5, y0-1.0, '1')\n",
    "    plt.xlabel('x');    plt.xlim(xmin, xmax);\n",
    "    plt.ylabel('f(x)'); plt.ylim(ymin, ymax)\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_derivative, x0=FloatSlider(min=1.0, max=2.8, step=0.1, value=1.0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Properties of derivatives\n",
    "\n",
    "### Rules for limit expressions\n",
    "\n",
    "Since derivatives are defined using limit expressions, let us first summarize the rules governing limits.\n",
    "\n",
    "First, the limit of a linear superposition is equal to a linear superposition of limits. This means that, given two constants $a_1$ and $a_2$ and two functions $f_1$ and $f_2$,\n",
    "\n",
    "$$\\lim_{x \\rightarrow c} \\big[a_1 \\,f_1(x) \\;+\\; a_2\\, f_2(x)\\big] = a_1 \\lim_{x \\rightarrow c} f_1(x) \\;+\\; a_2 \\lim_{x \\rightarrow c} f_2(x).$$\n",
    "\n",
    "Second, limits obey a product rule and a quotient rule:\n",
    "\n",
    "$$\\begin{aligned}\\lim_{x \\rightarrow c} \\big[\\;f_1(x) \\; f_2(x)\\;\\big] &= \\Big[\\lim_{x \\rightarrow c} f_1(x)\\Big]\\;\\Big[\\lim_{x \\rightarrow c} f_2(x)\\Big]  \\\\ \\lim_{x \\rightarrow c} \\left[\\;\\frac{f_1(x)}{f_2(x)}\\;\\right] &= \\frac{\\lim_{x \\rightarrow c} f_1(x)}{\\lim_{x \\rightarrow c} f_2(x)}. \\end{aligned}$$\n",
    "\n",
    "As a special exception, the product rule and quotient rule should be ignored whenever they produce results of $0 \\times \\infty$, $\\infty/\\infty$, or $0/0$, because such combinations are undefined.  For instance, naively applying the product rule to both of the following limit expressions gives $0 \\times \\infty$, but their actual values are zero and infinity:\n",
    "\n",
    "$$\\begin{aligned}\\lim_{x \\rightarrow 0}\\Big[\\,x^2\\;\\frac{1}{x}\\;\\Big] &= 0  \\;\\quad \\ne\\;\\;\\;\\lim_{x \\rightarrow 0}\\Big[\\,x^2\\,\\Big]\\; \\lim_{x \\rightarrow 0}\\Big[\\,\\frac{1}{x}\\,\\Big]\\\\ \\lim_{x \\rightarrow 0}\\Big[\\,x\\;\\frac{1}{x^2}\\;\\Big] &= \\infty \\quad \\ne\\;\\;\\;\\lim_{x \\rightarrow 0}\\Big[\\,x\\,\\Big]\\; \\lim_{x \\rightarrow 0}\\Big[\\,\\frac{1}{x^2}\\,\\Big].\\end{aligned}$$\n",
    "\n",
    "It is often convenient to use the computer to check for the correctness of a limit expression. This can be done by replacing infinitesimal quantities with numbers that are nonzero but very small.  For example, here is a quick way to check that the derivative of $x^2 + 1$ is $2x$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.999999975690116\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "x  = 2.0\n",
    "dx = 1e-8\n",
    "\n",
    "derivative_estimate = (((x+dx)**2 + 1) - (x**2 + 1)) / dx\n",
    "print(derivative_estimate)\n",
    "print(2*x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Composition rules for derivatives<a name=\"composition_rules\"></a>\n",
    "\n",
    "Using the rules for limit expressions, we can derive the elementary composition rules for derivatives:\n",
    "\n",
    "$$\\begin{aligned}\\frac{d}{dx}\\big[\\,\\alpha\\, f(x) + \\beta\\, g(x)\\,\\big] &= \\alpha\\, f'(x) + \\beta\\, g'(x) \\quad &\\textrm{(linearity)}& \\\\   \\frac{d}{dx}\\big[\\,f(x) \\, g(x)\\,\\big] &= f(x) \\, g'(x) + f'(x) \\, g(x) &\\textrm{(product}\\;\\textrm{rule)}& \\\\   \\frac{d}{dx}\\big[\\,f(g(x))\\,\\big] &= f'(g(x)) \\, g'(x) &\\textrm{(chain}\\;\\textrm{rule)}&\\end{aligned}$$\n",
    "\n",
    "These can all be proven by direct substitution into the definition of the derivative, and taking appropriate orders of limits.  With the aid of these rules, we can prove various standard results, such as the \"power rule\" for derivatives:\n",
    "$$\\frac{d}{dx} \\big[x^a\\big] = a x^{a-1}.$$\n",
    "\n",
    "The linearity of the derivative operation has the important implication that derivatives \"commute\" with sums, i.e. you can move them to the left or right of summation signs. This fact can be used to help prove that the [exponential function](00_mathfunctions.ipynb#exponential) is its own derivative:\n",
    "$$\\frac{d}{dx} \\left[\\exp(x)\\right] = \\frac{d}{dx} \\sum_{n=0}^\\infty\\frac{x^n}{n!} = \\sum_{n=0}^\\infty\\frac{d}{dx} \\, \\frac{x^n}{n!} = \\sum_{n=1}^\\infty \\frac{x^{n-1}}{(n-1)!} =\\exp(x)$$\n",
    "\n",
    "Derivatives also \"commute\" with limits.  For example, we can use this on the alternative definition of the exponential function:\n",
    "\n",
    "$$\\begin{aligned}\\frac{d}{dx} \\left[\\exp(x)\\right] &= \\frac{d}{dx} \\lim_{n\\rightarrow\\infty} \\left(1+\\frac{x}{n}\\right)^n = \\lim_{n\\rightarrow\\infty} \\frac{d}{dx} \\left(1+\\frac{x}{n}\\right)^n \\\\ &= \\lim_{n\\rightarrow\\infty} \\left(1+\\frac{x}{n}\\right)^{n-1} \\;= \\exp(x)\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.389056033701991\n",
      "7.38905609893065\n"
     ]
    }
   ],
   "source": [
    "## Check that the derivative of exp(x) is exp(x):\n",
    "x  = 2.0\n",
    "dx = 1e-8\n",
    "\n",
    "from numpy import exp\n",
    "derivative_estimate = (exp(x+dx) - exp(x)) / dx\n",
    "print(derivative_estimate)\n",
    "print(exp(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Taylor series\n",
    "\n",
    "A function is **infinitely differentiable** at a point $x_0$ if all orders of derivatives are well-defined (i.e., first derivative, second derivative, etc.) at $x_0$.  Not all functions behave this way: for example, $f(x) = |x|$ has a first derivative which is discontinuous at $x = 0$, which means that it has no well-defined second derivative at that point.\n",
    "\n",
    "If a function is infinitely differentiable at $x_0$, then near that point it can be expanded in a **Taylor series**:\n",
    "\n",
    "$$\\begin{aligned}f(x) \\;&=\\; \\sum_{n=0}^\\infty \\frac{(x-x_0)^n}{n!} \\left[\\frac{d^n}{dx^n} f\\right](x_0) \\\\&=\\; f(x_0) + (x-x_0)\\, f'(x_0) + \\frac{1}{2}\\, (x-x_0)^2\\, f''(x_0) + \\cdots\\end{aligned}$$\n",
    "\n",
    "Here, the \"zeroth derivative\" refers to the function itself.\n",
    "\n",
    "The Taylor series can be derived by assuming that $f(x)$ can be written out as a general polynomial involving terms of the form $(x-x_0)^n$; using the definition of the derivative, we can derive the polynomial coefficients appearing in the series. Because this polynomial approximation is only an assumption, there is no guarantee that the Taylor series actually converges to the true value for a given value of $x \\ne x_0$.  For many functions, the Taylor series converges only if $|x-x_0|$ is smaller than a certain amount.\n",
    "\n",
    "<a name=\"taylor_useful\"></a>\n",
    "\n",
    "<table width=\"90%\" style=\"font-size: 100%; border: 1px solid gray;\">\n",
    "<tr>\n",
    "<td colspan=2 style=\"text-align:left\">**Useful Taylor Series**</td>\n",
    "</tr><tr>\n",
    "<td style=\"text-align:left\">$$\\displaystyle\\frac{1}{1-x} = 1 + x + x^2 + x^3 + \\cdots\\mathrm{for} \\; |x| < 1 $$</td>\n",
    "<td style=\"text-align:left\">$$\\displaystyle\\ln(1-x) = -x - \\frac{x^2}{2} - \\frac{x^3}{3} - \\frac{x^4}{4} - \\cdots \\quad \\mathrm{for} \\; |x| < 1$$</td>\n",
    "</tr><tr>\n",
    "<td style=\"text-align:left\">$$\\displaystyle\\sin(x) = x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\frac{x^7}{7!} + \\cdots$$</td>\n",
    "<td style=\"text-align:left\">$$\\displaystyle\\sinh(x) = x + \\frac{x^3}{3!} + \\frac{x^5}{5!} + \\frac{x^7}{7!} + \\cdots$$</td>\n",
    "</tr><tr>\n",
    "<td style=\"text-align:left\">$$\\displaystyle\\cos(x) = 1 - \\frac{x^2}{2!} + \\frac{x^4}{4!} - \\frac{x^6}{6!} + \\cdots$$</td>\n",
    "<td style=\"text-align:left\">$$\\displaystyle\\cosh(x) = 1 + \\frac{x^2}{2!} + \\frac{x^4}{4!} + \\frac{x^6}{6!} + \\cdots$$</td>\n",
    "</tr></table>\n",
    "\n",
    "Apart from the first row, the others are actually exact for all $x$.  The [sine/cosine functions](00_mathfunctions.ipynb#trigonometric) and [hyperbolic functions](00_mathfunctions.ipynb#hyperbolic) are \"entire\", which means that their Taylor series converge everywhere in $\\mathbb{R}$. If you pick a large value of $x$, however, you may have to sum to a very high order before the series converges to an accurate value.\n",
    "\n",
    "The following interactive plots compare the functions $\\sin(x)$ and $\\ln(x+1)$ to their series expansions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": "json-false",
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "805cf7da8b80437eb8b8b2a6a6ba8cec"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Compare sin(x) to its series expansion\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact, IntSlider\n",
    "from numpy import linspace, zeros, sin\n",
    "from scipy.special import factorial\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_sine_series(N):\n",
    "    x = linspace(0, 25, 200)\n",
    "    y = sin(x)\n",
    "    ys = zeros(len(x))\n",
    "    for n in range(1, N+1, 2):   # sum over 1, 3, 5, ..., N\n",
    "        ys += x**n * (-1)**(0.5*(n-1)) / factorial(n)\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(x, y, color='blue', label='Exact')\n",
    "    plt.plot(x, ys, color='red', label='Power series')\n",
    "    plt.title('Power series for sin(x), summed to order {}'.format(N))\n",
    "    plt.xlabel('x'); plt.xlim(0, 25)\n",
    "    plt.ylabel('y'); plt.ylim(-2, 2)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_sine_series, N=IntSlider(min=1, max=59, step=2, value=4));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16b15b3e17f6499f86c3d0488d955b43"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Compare ln(x+1) to its series expansion\n",
    "%matplotlib inline\n",
    "from ipywidgets import interact, IntSlider\n",
    "from numpy import linspace, zeros, log\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_log_series(N):\n",
    "    x = linspace(-0.99, 1.5, 200)\n",
    "    y = log(x+1)\n",
    "    xs = linspace(-2, 2, 200)\n",
    "    ys = zeros(len(x))\n",
    "    for n in range(1, N+1):\n",
    "        ys -= (-xs)**n / n\n",
    "\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(x,   y, color='blue', label='Exact')\n",
    "    plt.plot(xs, ys, color='red', label='Power series')\n",
    "    plt.title('Power series for ln(x+1), summed to order {}'.format(N))\n",
    "    plt.xlabel('x'); plt.xlim(-2, 1.5)\n",
    "    plt.ylabel('y'); plt.ylim(-4, 3)\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.show()\n",
    "\n",
    "interact(plot_log_series, N=IntSlider(min=1, max=59, step=1, value=1));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Ordinary differential equations<a name=\"ODE\"></a>\n",
    "\n",
    "A differential equation is an equation involving several different derivatives of a function.  For example,\n",
    "\n",
    "$$\\frac{df}{dx} = \\kappa\\, f(x)$$\n",
    "\n",
    "is a differential equation involving both $f$ and its first derivative.  Specifically, this is called an **ordinary differential equation**, because $f$ is a function involving a single variable $x$, rather than multiple variables.\n",
    "\n",
    "Finding a solution for the differential equation means finding a function that satisfies the equation. There is no single method for solving differential equations.  In some cases, we can guess the solution; for example, by trying different elementary functions, we might find out that the above differential equation can be solved by\n",
    "\n",
    "$$f(x) = A \\exp(\\kappa x).$$\n",
    "\n",
    "Certain special classes of differential equation can be solved using techniques like Fourier transforms, Green's functions, etc. We will cover a few of these techniques in this course. However, other classes of differential equations have no known exact analytic solution.\n",
    "\n",
    "<a name=\"example2\"></a>\n",
    "<table width=75% style=\"font-size: 100%; border: 1px solid gray;\">\n",
    "<tr><td style=\"text-align:left\">**Example**</td></tr>\n",
    "<tr><td style=\"text-align:left\">The following differential equation describes a [damped harmonic oscillator](04_complex_oscillations.ipynb):<br/>$$\\frac{d^2 x}{dt^2} + 2\\gamma\\frac{dx}{dt} + \\omega_0^2 x(t) = 0.$$<br/>In this case, note that $x(t)$ is the function, and $t$ is the input variable. This is unlike our previous notation where $x$ was the input variable, so don't get confused!\n",
    "\n",
    "This equation is obtained from Newton's second law, for an object moving in one dimension subject to a damping force and a restoring force.  Thus $x(t)$ represents the position as a function of time.  We will come back to study this equation in detail [later](04_complex_oscillations.ipynb).</td></tr></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Specific solutions and general solutions\n",
    "\n",
    "When confronted with an ordinary differential equation, the first thing you should check for is the highest derivative appearing in the equation.  This is called the **order** of the differential equation.  If the equation has order $N$, then its **general solution** contains $N$ **free parameters** that can be assigned any value (similar to \"constants of integration\"). If you happen to be able to guess a solution to the equation, but that solution does not contain $N$ free parameters, then you know that your solution isn't the most general one.\n",
    "\n",
    "For example, the ordinary differential equation\n",
    "\n",
    "$$\\frac{df}{dx} = \\kappa f(x)$$\n",
    "\n",
    "has order one. We have previously guessed the solution $f(x) = A \\exp(\\kappa x)$, which has one free parameter, $A$.  So we know our work is done: there is no solution more general than the one we found.\n",
    "\n",
    "A **specific solution** to a differential equation is a solution containing no free parameters.  One way to get a specific solution is to start from a general solution, and assign actual values to each of the free parameters.  In physics problems, the assigned values are commonly determined by **boundary conditions**. For example, you may be asked to solve a second-order differential equation given the boundary conditions $f(0) = a$ and $f(1) = b$; alternatively, you might be given the boundary conditions $f(0) = c$ and $f'(0) = d$, or any other combination of two conditions.  For an ordinary differential equation of order $N$, we need $N$ conditions to define a specific solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Partial derivatives\n",
    "\n",
    "So far, we have focused on functions which take a single input.  Functions can also take multiple inputs; for instance, a function $f(x,y)$ maps two input numbers, $x$ and $y$, and outputs a number.  In general, the inputs are allowed to vary independently of one another.  The **partial derivative** of such a function is its derivative with respect to one of its inputs, keeping the others fixed.  For example,\n",
    "\n",
    "$$f(x,y) = \\sin(2x - 3 y^2)$$\n",
    "\n",
    "has partial derivatives\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x} = 2\\cos(2x-3y^2), \\quad \\frac{\\partial f}{\\partial y} = - 6\\cos(2x-3y^2).$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Change of variables<a name=\"change_of_variables\"></a>\n",
    "\n",
    "We have previously seen that single-variable functions obey a derivative composition rule,\n",
    "\n",
    "$$\\frac{d}{dx}\\, f\\big(g(x)\\big) = g'(x) \\, f'\\big(g(x)\\big).$$\n",
    "\n",
    "This composition rule has a important generalization for partial derivatives, which is related to the physical concept of a **change of coordinates**. Suppose we have a function $f(x,y)$ which takes two inputs $x$ and $y$, and wish to express them using a different coordinate system denoted (say) $u$ and $v$.  In general, each coordinate in the old system depends on *both* coordinates in the new system:\n",
    "\n",
    "$$x = x(u,v), \\quad y = y(u,v).$$\n",
    "\n",
    "Expressed in the new coordinates, the function is\n",
    "\n",
    "$$F(u,v) \\equiv f\\big(x(u,v), y(u,v)\\big).$$\n",
    "\n",
    "It can then be shown that this transformed function's partial derivatives obey the composition rule\n",
    "\n",
    "$$\\begin{aligned}\\frac{\\partial F}{\\partial u} &= \\frac{\\partial f}{\\partial x} \\frac{\\partial x}{\\partial u} + \\frac{\\partial f}{\\partial y} \\frac{\\partial y}{\\partial u}\\\\ \\frac{\\partial F}{\\partial v} &= \\frac{\\partial f}{\\partial x} \\frac{\\partial x}{\\partial v} + \\frac{\\partial f}{\\partial y} \\frac{\\partial y}{\\partial v}.\\end{aligned}$$\n",
    "\n",
    "On the right-hand side of these equations, the partial derivatives are to be expressed in terms of the new coordiantes $(u,v)$.  For example,\n",
    "\n",
    "$$\\frac{\\partial f}{\\partial x} = \\left.\\frac{\\partial f}{\\partial x}\\right|_{x = x(u,v), \\;y= y(u,v)}$$\n",
    "\n",
    "The generalization of this rule to more than two inputs is straightforward.  For a function $f(x_1, \\dots, x_N)$, a change of coordinates $x_i = x_i(u_1, \\dots, u_N)$ involves the composition\n",
    "\n",
    "$$F(u_1, \\dots, u_N) = f\\big(x_1(u_1,\\dots,u_N\\big), \\dots), \\quad \\frac{\\partial F}{\\partial u_i} = \\sum_{j=1}^N \\frac{\\partial x_j}{\\partial u_i} \\frac{\\partial f}{\\partial x_j}.$$\n",
    "\n",
    "<table width=75% style=\"font-size: 100%; border: 1px solid gray;\">\n",
    "<tr><td style=\"text-align:left\">**Example**</td></tr>\n",
    "<tr><td style=\"text-align:left\">\n",
    "In two dimensions, Cartesian and polar coordinates are related by the formulas<br/>$$x = r\\cos\\theta, \\quad y = r\\sin\\theta.$$<br/>If we have a function $f(x,y)$, we can re-write it in polar coordinates as $F(r,\\theta)$. The partial derivatives are related by<br/>$$\\begin{aligned}\\frac{\\partial F}{\\partial r} &= \\frac{\\partial f}{\\partial x} \\frac{\\partial x}{\\partial r} + \\frac{\\partial f}{\\partial y} \\frac{\\partial y}{\\partial r} = \\frac{\\partial f}{\\partial x} \\cos\\theta + \\frac{\\partial f}{\\partial y} \\sin\\theta. \\\\ \\frac{\\partial F}{\\partial \\theta} &= \\frac{\\partial f}{\\partial x} \\frac{\\partial x}{\\partial \\theta} + \\frac{\\partial f}{\\partial y} \\frac{\\partial y}{\\partial \\theta} = -\\frac{\\partial f}{\\partial x} r\\,\\sin\\theta + \\frac{\\partial f}{\\partial y} r\\cos\\theta.\\end{aligned}$$</td></tr></table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Partial differential equations<a name=\"PDE\"></a>\n",
    "\n",
    "A partial differential equation is a differential equation which involves multiple partial derivatives (as opposed to an *ordinary* differential equation, which involves only derivatives with respect to a single variable).  An example of a partial differential equation is Laplace's equation,\n",
    "\n",
    "$$\\frac{\\partial^2 \\Phi}{\\partial x^2} + \\frac{\\partial^2 \\Phi}{\\partial y^2} + \\frac{\\partial^2 \\Phi}{\\partial z^2}= 0,$$\n",
    "\n",
    "which describes the electrostatic potential $\\Phi(x,y,z)$ at position $(x,y,z)$, in the absence of any electric charges.  Partial differential equations are significantly harder to solve than ordinary differential equations.  For example, boundary conditions are more complicated to specify: whereas each boundary condition for an ordinary differential equation consists of a single number (e.g., the value of $f(x)$ at some point $x = x_0$), each boundary condition for a partial differential equation consists of a *function* (e.g., the values of $\\Phi(x,y,z)$ along some curve $g(x,y,z) = 0$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": [
     "worksheet-0"
    ],
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Exercises\n",
    "<a name=\"exercises\"></a>\n",
    "\n",
    "<ol>\n",
    "<div id=\"prob_continuity\"></div>\n",
    "<li>Show that if a function is [differentiable](#derivative_definition), then it is also [continuous](00_mathfunctions.ipynb#continuity).</li>\n",
    "<li>Prove that the derivative of $\\ln(x)$ is $1/x$.\n",
    "<br/><div style=\"text-align: right\">[(Solution)](99_solutions.ipynb#01_02)</div><br/></li>\n",
    "<li>Prove that\n",
    "\n",
    "$$\\frac{d}{dx} [x^y] = y x^{y-1}, \\quad\\mathrm{for}\\;\\;x \\in \\mathbb{R}^+, \\; y \\notin \\mathbb{N},$$\n",
    "\n",
    "starting from the previously-discussed [definition of non-natural powers](00_mathfunctions.ipynb#exponential) in terms of the exponential and logarithm functions.</li>\n",
    "<li>Consider $f(x) = \\tanh(\\alpha x)$.\n",
    "<ol style=\"list-style-type:lower-alpha\"><li>Sketch $f(x)$ versus $x$, for two cases: (i) $\\alpha = 1$ and (ii) $\\alpha \\gg 1$.</li>\n",
    "<li>Sketch the derivative function $f'(x)$ for the two cases, based on your sketches in part (a) (i.e., without evaluating the derivative directly).</li>\n",
    "<li>Evaluate the derivative function, and verify that the result matches your sketches in part (b).</li></ol></li>\n",
    "<li>\n",
    "Prove geometrically that the derivatives of the sine and cosine functions are:<br/>$$\\frac{d}{dx}\\sin(x) = \\cos(x), \\quad\\frac{d}{dx}\\cos(x) = -\\sin(x).$$<br/>Hence, derive their [series expansions](#taylor_useful).</li>\n",
    "<li>For each of the following functions, derive the Taylor series around $x = 0$:\n",
    "<ol style=\"list-style-type:lower-alpha\">\n",
    "<li>$f(x) = \\ln\\left[\\alpha \\cos(x)\\right]$, to the first 3 non-vanishing terms.</li>\n",
    "<li>$f(x) = \\cos\\left[\\pi\\exp(x)\\right]$, to the first 4 non-vanishing terms.</li>\n",
    "<li>$f(x) = \\frac{1}{\\sqrt{1 \\pm x}}$, to the first 4 non-vanishing terms.  Keep track of the signs (i.e., $\\pm$ versus $\\mp$).</li></ol></li>\n",
    "<li>For each of the following functions, sketch the graph and state the domains over which the function is differentiable:\n",
    "<ol style=\"list-style-type:lower-alpha\">\n",
    "<li>$f(x) = |\\sin(x)|$</li>\n",
    "<li>$f(x) = \\left[\\tan(x)\\right]^2$</li>\n",
    "<li>$f(x) = \\frac{1}{1-x^2}$</li>\n",
    "</ol></li>\n",
    "<li>Let $\\vec{v}(x)$ be a *vectorial* function which takes an input $x$ (a number), and gives an output value $\\vec{v}$ that is a 2-component vector.  The derivative of this vectorial function is defined in terms of the derivatives of each vector component:\n",
    "\n",
    "$$\\vec{v}(x) = \\begin{bmatrix}v_1(x) \\\\ v_2(x)\\end{bmatrix} \\;\\; \\Rightarrow \\;\\; \\frac{d\\vec{v}}{dx} = \\begin{bmatrix}dv_1/dx \\\\ dv_2/dx\\end{bmatrix}.$$\n",
    "\n",
    "Now suppose $\\vec{v}(x)$ obeys the vectorial differential equation\n",
    "\n",
    "$$\\frac{d\\vec{v}}{dx} = \\mathbf{A} \\vec{v},$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\\mathbf{A} = \\begin{bmatrix}A_{11} & A_{12} \\\\ A_{21} & A_{22}\\end{bmatrix}.$$\n",
    "\n",
    "is a matrix that has two distinct real eigenvectors with real eigenvalues.\n",
    "</li>\n",
    "\n",
    "<ol style=\"list-style-type:lower-alpha\">\n",
    "<li>How many independent numbers do we need to specify for the general solution?</li>\n",
    "<li>Let $\\vec{u}$ be one of the eigenvectors of $\\mathbf{A}$, with eigenvalue $\\lambda$:\n",
    "\n",
    "$$\\mathbf{A} \\vec{u} = \\lambda \\vec{u}.$$\n",
    "\n",
    "Show that $\\vec{v}(x) = \\vec{u}\\, e^{\\lambda x}$ is a specific solution to the vectorial differential equation.  Hence, find the general solution.\n",
    "<br/><div style=\"text-align: right\">[(Solution)](99_solutions.ipynb#01_02)</div><br/></li>\n",
    "</ol>\n",
    "</ol>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "name": "01_derivatives.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
