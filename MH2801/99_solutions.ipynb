{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions to selected problems\n",
    "\n",
    "## 0. Mathematical Functions\n",
    "\n",
    "<ol>\n",
    "<li value=\"2\"><a name=\"00_02\"></a>\n",
    "To prove that $\\exp(x+y) = \\exp(x)\\,\\exp(y)$, we employ the infinite series formula<br/>\n",
    "$$\\exp(x) = \\sum_{n=0}^\\infty\\frac{x^n}{n!}.$$<br/>Here, for notational convenience, we let the sum start from $n = 0$, so that the leading term $1$ in the definition of the exponential is grouped with the rest of the sum as its first term.  This relies on the understanding that $0! \\equiv 1$, and that $x^0 = 1$ (the latter is consistent with the <a href=\"00_mathfunctions.ipynb#powers\">generalized definition of the power operation</a>; but to avoid circular logic, treat this as the *definition* of $x^0$ just for the sake of this proof).  We begin by substituting the series formula into the right-hand side of our target equation:<br/>\n",
    "$$\\exp(x)\\exp(x) = \\left(\\sum_{n=0}^\\infty\\frac{x^n}{n!}\\right)\\;\\left(\\sum_{m=0}^\\infty\\frac{y^m}{m!}\\right).$$<br/>\n",
    "Note that we use the symbol $n$ for the first sum, and the symbol $m$ for the second sum; $n$ and $m$ are <a href=\"https://en.wikipedia.org/wiki/Free_variables_and_bound_variables\">bound variables</a>, whose terms run over the values specified by the summation signs.  The actual choice of symbol used in either sum is unimportant, except that *we must not use the same symbol for both sums*, because the two variables belong to distinct sums.  In other words:<br/>\n",
    "$$\\exp(x)\\exp(x) \\ne \\left(\\sum_{n=0}^\\infty\\frac{x^n}{n!}\\right)\\;\\left(\\sum_{n=0}^\\infty\\frac{y^n}{n!}\\right). \\;\\;(\\text{Nonsense expression!})$$<br/>\n",
    "Next, we make use of the fact that the product of two series can be written as a double sum:<br/>\n",
    "$$\\exp(x)\\exp(x) = \\sum_{n=0}^\\infty \\sum_{m=0}^\\infty \\frac{x^n}{n!} \\frac{y^m}{m!}.$$<br/>\n",
    "Here, we are summing over all possible pair-wise combinations of $n$ and $m$, which is precisely what happens when one expands the product of two series according to the usual rules of algebra.  The next step is to perform a *change of variables* on $m$ and $n$. In the above expression, we are summing over all non-negative integer $m$ and $n$; however, the bound variable $n$ can be re-expressed in terms of a newly-defined variable,<br/>\n",
    "$$N = m + n.$$</br>\n",
    "In the original double sum, $n$ and $m$ both run from $0$ to $+\\infty$, so it follows that their sum $N$ runs from $0$ to $+\\infty$. For each given value of $N$, we can write $n = N - m$, and moreover the allowed values of $m$ would only go from $0$ to $N$ (it can't exceed $N$, otherwise $n$ would be negative). In this way, the double sum is converted to<br/>\n",
    "$$\\exp(x)\\exp(x) = \\sum_{N=0}^\\infty \\sum_{m=0}^N \\frac{x^{N-m}}{(N-m)!} \\frac{y^m}{m!}$$<br/>\n",
    "Note that after this change of variables, the two summation signs are no longer interchangeable.  In the $\\sum_{m=0}^N$ sign, the variable $N$ appears in the upper limit, so this needs to be written to the right of $\\sum_{N=0}^\\infty$.  One sum is thus \"encapsulated\" inside the other; we could write the algebraic expression more rigorously like this:\n",
    "$$\\exp(x)\\exp(x) = \\sum_{N=0}^\\infty \\left(\\sum_{m=0}^N \\frac{x^{N-m}}{(N-m)!} \\frac{y^m}{m!}\\right).$$<br/>\n",
    "Finally, we use the <a href=\"https://en.wikipedia.org/wiki/Binomial_theorem\">binomial theorem</a> to simplify the inner sum:<br/>\n",
    "$$\\exp(x)\\exp(x) = \\sum_{N=0}^\\infty \\frac{\\left(x + y\\right)^N}{N!}, \\;\\;\\;\\text{since} \\;\\; (x+y)^N = \\sum_{m=0}^N \\frac{N!}{m!(N-m)!} x^{N-m} \\, y^m.$$<br/>\n",
    "Referring again to the series definition of the exponential, we obtain the desired result:<br/>\n",
    "$$\\exp(x)\\exp(x) = \\exp(x+y)$$<br/>\n",
    "</li>\n",
    "<li value=\"4\"><a name=\"00_04\"></a>\n",
    "The <a href=\"00_mathfunctions.ipynb#powers\">definition</a> of non-natural powers is<br/>\n",
    "$$a^b = \\exp[b\\ln(a)].$$\n",
    "Let $a = \\exp(1) = e$ and $b = x$. Then<br/>\n",
    "$$[\\exp(1)]^x = \\exp\\left[x\\ln\\Big(\\exp(1)\\Big)\\right].$$\n",
    "Since the logarithm is the inverse of the exponential function, $\\ln(\\exp(1)) = 1$. Hence,\n",
    "$$e^x = \\exp(x).$$<br/>\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Derivatives\n",
    "\n",
    "<ol>\n",
    "<li value=\"2\"><a name=\"01_02\"></a>\n",
    "If $y = \\ln(x)$, it follows from the definition of the logarithm that\n",
    "\n",
    "$$\\exp(y) = x.$$\n",
    "\n",
    "Taking $d/dx$ on both sides, and using the [product rule](01_derivatives.ipynb#composition_rules), gives\n",
    "\n",
    "$$\\frac{dy}{dx} \\, \\exp(y) = 1 \\;\\;\\; \\Rightarrow \\frac{dy}{dx} = \\frac{1}{\\exp(y)} = \\frac{1}{x}.$$<br/>\n",
    "</li>\n",
    "<li value=\"8\"><a name=\"01_08\"></a>\n",
    "For an ordinary differential equation for a scalar (one-component) function of order $n$, the general solution must contain $n$ independent variables. In this case, $\\vec{v}$ is a two-component function, so it requires $2n$ indpendent variables. The differential equation<br/>\n",
    "$$\\frac{d\\vec{v}}{dx} = \\mathbf{A} \\vec{v}$$<br/>\n",
    "has order $n = 1$, so a total of 2 independent variables is required for the general solution.\n",
    "\n",
    "Let $u$ be an eigenvector of $\\mathbf{A}$ with eigenvalue $\\lambda$, and suppose that $\\vec{v}(x) = \\vec{u}\\,e^{\\lambda x}$ (note that $\\vec{u}$ itself does not depend on $x$).  Then<br/>\n",
    "$$\\begin{aligned}\\frac{d\\vec{v}}{dx} &= \\vec{u} \\frac{d}{dx}\\left(e^{\\lambda x}\\right) \\\\\n",
    "&= \\lambda \\, \\vec{u}\\, e^{\\lambda x} \\\\\n",
    "&= \\left(\\mathbf{A} \\vec{u}\\right) e^{\\lambda x} \\\\\n",
    "&= \\mathbf{A} \\left(\\vec{u} e^{\\lambda x}\\right) \\\\\n",
    "&= \\mathbf{A} \\vec{v}(x).\n",
    "\\end{aligned}$$<br/>\n",
    "Hence, $\\vec{v}(x)$ satisfies the desired differential equation.\n",
    "\n",
    "Let $\\vec{u}_1$ and $\\vec{u}_2$ be the eigenvectors of $\\mathbf{A}$, with eigenvalues $\\lambda_1$ and $\\lambda_2$.  The general solutions will be<br/>\n",
    "$$\\vec{v}(x) = c_1 \\vec{u}_1 e^{\\lambda_1 x} + c_2 \\vec{u}_2 e^{\\lambda_2 x},$$<br/>\n",
    "where $c_1$ and $c_2$ are independent variables.\n",
    "</li>\n",
    "</ol>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Integrals\n",
    "\n",
    "<ol>\n",
    "<li value=\"4\"><a name=\"02_04\"></a>\n",
    "Let us define<br/>\n",
    "$$I(\\gamma) = \\int_0^1 \\frac{x^\\gamma - 1}{\\ln(x)},$$<br/>\n",
    "so that $I(2)$ is our desired integral.  To take the derivative, first note that<br/>\n",
    "$$\\frac{d}{d\\gamma}(x^\\gamma) = \\ln(x)\\, x^\\gamma,$$<br/>\n",
    "which can be proven using the <a href=\"00_mathfunctions.ipynb#powers\">generalized definition of the power operation</a>.  Thus,<br/>\n",
    "$$\\begin{aligned}\\frac{d}{d\\gamma} I(\\gamma) &= \\int_0^1 \\frac{\\ln(x) x^\\gamma}{\\ln(x)} \\\\\n",
    "&= \\int_0^1 x^\\gamma \\\\\n",
    "&= \\frac{1}{1+\\gamma}.\\end{aligned}$$<br/>\n",
    "This can be integrated straightforwardly:<br/>\n",
    "$$I(\\gamma) = \\int \\frac{d\\gamma}{1+\\gamma} = \\ln(1+\\gamma) + c,$$\n",
    "where $c$ is a constant of integration, which we now have to determine.  Referring to the original definition of $I(\\gamma)$, observe that $I(0) = \\int_0^1 (1 - 1)/\\ln(x) = 0$.  This implies that $c = 0$.  Therefore, the answer is<br/>\n",
    "$$I(2) = \\ln(3).$$\n",
    "</li>\n",
    "<li value=\"6\"><a name=\"02_06\"></a>\n",
    "We are provided with the following guess (or \"ansatz\") for the solution to the differential equation:<br/>\n",
    "$$y(t) = y(0) + \\int_0^t dt' e^{-\\gamma(t-t')} g(t').$$<br/>\n",
    "First, note that when $t = 0$, the integral's range shrinks to zero, so the result is $y(0)$, as expected.  In order to determine the appropriate function $g$, we perform a derivative in $t$. The tricky part is that $t$ appears in two places: in the upper range of the integral, as well as in the integrand. So when we take the derivative, there should be two distinct terms (see <a href=\"02_integrals.ipynb#exercises\">problem 5</a>):<br/>\n",
    "$$\\begin{aligned}\\frac{dy}{dt} &= \\left[e^{-\\gamma(t-t')} g(t')\\right]_{t'=t} + \\int_0^t dt'(-\\gamma) \\, e^{-\\gamma(t-t')} \\, g(t')\\\\\n",
    "&= g(t) - \\gamma [y(t) - y(0)].\\end{aligned}$$<br/>\n",
    "In the last step, we again made use of the ansatz for $y(t)$.  Finally, comparing this with the original differential equation for $y(t)$, we find that<br/>\n",
    "$$g(t) - \\gamma [y(t) - y(0)] = -\\gamma y(t) + f(t) \\;\\;\\; \\Rightarrow \\;\\;\\; g(t) = f(t) - \\gamma y(0).$$<br/>\n",
    "Hence, the solution to the differential equation is<br/>\n",
    "$$\\begin{aligned}y(t) &= y(0) + \\int_0^t dt' \\, e^{-\\gamma(t-t')} \\,[f(t') - \\gamma y(0)] \\\\\n",
    "&= y(0)\\,e^{-\\gamma t} + \\int_0^t dt' \\, e^{-\\gamma(t-t')} f(t').\\end{aligned}$$<br/>\n",
    "</li>\n",
    "</ol>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Complex Numbers\n",
    "\n",
    "<ol>\n",
    "<li value=\"2\"><a name=\"03_02\"></a>\n",
    "Using the polar representation: let $z_1 = r_1 \\exp(i\\theta_1)$ and $z_2 = r_2 \\exp(i\\theta_2)$. Then\n",
    "$$\\begin{aligned}\\big|z_1\\, z_2\\big| &= \\left|r_1 e^{i\\theta_1} \\, r_2 e^{i\\theta_2}\\right| \\\\&= \\left|(r_1r_2)\\,e^{i(\\theta_1+\\theta_2)}\\right| \\\\&= r_1 r_2 \\\\&= |z_1|\\, |z_2|.\\end{aligned}$$\n",
    "Using the Cartesian representation: let $z_1 = x_1+iy_1$ and $z_2 = x_2+iy_2$.  For convenience, we evaluate the squared magnitude:\n",
    "$$\\begin{aligned}\\big|z_1\\, z_2\\big|^2 &= \\left|(x_1x_2 - y_1y_2) + i (x_1y_2+x_2y_1)\\right|^2 \\\\&= (x_1x_2 - y_1y_2)^2 + (x_1y_2+x_2y_1)^2 \\\\&= x_1^2x_2^2 + y_1^2 y_2^2 + x_1^2y_2^2 + x_2^2 y_1^2 \\\\&= \\left(x_1^2 + y_1^2\\right)\\left(x_2^2 + y_2^2\\right) \\\\&= |z_1|^2 \\, |z_2|^2.\\end{aligned}$$\n",
    "</li>\n",
    "<li value=\"3\"><a name=\"03_03\"></a>\n",
    "Using the polar representation: let $z_1 = r_1 \\exp(i\\theta_1)$ and $z_2 = r_2 \\exp(i\\theta_2)$. Then\n",
    "$$\\begin{aligned}\\big(z_1\\, z_2\\big)^* &= \\left(\\left(r_1r_2\\right) e^{i(\\theta_1+\\theta_2)}\\right)^* \\\\ &= \\left(r_1r_2\\right) e^{-i(\\theta_1+\\theta_2)} \\\\&= \\left(r_1 e^{-i\\theta_1}\\right) \\left(r_2 e^{-i\\theta_2}\\right) \\\\&= z_1^* \\, z_2^*.\\end{aligned}$$\n",
    "Using the Cartesian representation: let $z_1 = x_1+iy_1$ and $z_2 = x_2+iy_2$.\n",
    "$$\\begin{aligned}\\big(z_1\\, z_2\\big)^* &= \\left[\\left(x_1x_2 - y_1y_2\\right) + i \\left(x_1y_2+x_2y_1\\right)\\right]^* \\\\&= \\left(x_1x_2 - y_1y_2\\right) - i \\left(x_1y_2+x_2y_1\\right) \\\\&= \\left(x_1 - iy_1\\right) \\left(x_2 - iy_y\\right) \\\\&= z_1^* \\, z_2^*.\\end{aligned}$$\n",
    "</li>\n",
    "<li value=\"4\"><a name=\"03_04\"></a>\n",
    "The problem arises in this part of the chain: $i\\cdot i = \\sqrt{-1}\\,\\sqrt{-1} = \\sqrt{(-1)(-1)}$.  The square root is a non-integer power, and non-integer powers  are <a href=\"03_complex_numbers.ipynb#algebra\">not allowed to take part in standard complex algebra equations</a> in the same way as addition, subtraction, multiplication, division, and integer powers.<p>As discussed in <a href=\"07_branch_cuts.ipynb\">Chapter 7</a>, square roots and other non-integer powers have multiple values. The definition of the imaginary unit is often written as $i = \\sqrt{-1}$, but this is misleading. Actually, $\\sqrt{-1}$ has two legitimate values; one of these values is (by definition) $i$, while the other value is $-i$.</p></li>    \n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Complex Oscillations\n",
    "\n",
    "<ol>\n",
    "<li value=\"4\"><a name=\"04_04\"></a>\n",
    "The general solution is $$z(t) = A \\exp\\left[-i(\\omega_1 - i \\gamma) t\\right].$$ It can be verified by direct substitution that this is a solution to the differential equation. It contains one free parameter, and the differential equation is first-order, so it must be a general solution. Next,$$\\begin{align}\\frac{d^2z}{dt^2} + 2 \\gamma \\frac{dz}{dt} &= (-i)^2(\\omega_1 - i\\gamma)^2 z(t) - 2i \\gamma (\\omega_1 - i \\gamma) z(t) \\\\ &= \\left[- \\omega_1^2 + \\gamma^2 + 2i\\gamma\\omega_1 - 2i \\gamma \\omega_1 - 2\\gamma^2)\\right] z(t) \\\\ &= -\\left(\\omega_1^2 + \\gamma^2\\right)z(t).\\end{align}$$ Hence, $z(t)$ obeys a damped harmonic oscillator equation with $\\omega_0^2 = \\omega_1^2 + \\gamma^2.$  This expression for the natural frequency ensures that $\\omega_0^2 > \\gamma^2$ (assuming the parameters $\\gamma$ and $\\omega_1$ are both real); hence, the harmonic oscillator is always under-damped.\n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Complex Waves\n",
    "\n",
    "<ol>\n",
    "<li value=\"2\"><a name=\"05_02\"></a>\n",
    "Writing $n = n' + i n''$, where $n'$ and $n''$ are real, the travelling wave solutions are $$\\psi(x) = A \\exp\\left[\\pm i (n'+in'')\\frac{\\omega}{c} x\\right].$$ The magnitude and argument are: $$\\begin{align}\\big|\\psi(x)\\big| &= |A| \\exp\\left[\\mp n'' \\frac{\\omega}{c} x \\right] \\\\ \\mathrm{arg}\\big[\\psi(x)\\big] &= \\mathrm{arg}(A) \\pm n' \\frac{\\omega}{c} x.\\end{align}$$ The wave's propagation direction is determined by the argument: if the argument increases with $x$ then it is right-moving, and if the argument decreases with $x$ it is left-moving. Moreover, the wave is said to experience amplification if its amplitude grows along the propagation direction, and damping if its amplitude decreases along the propagation direction.<p>Consider the upper choice of sign (i.e., $+$ for the $\\pm$ symbol and $-$ for the $\\mp$ symbol). From the magnitude, we see that the wave's amplitude decreases with $x$ if $n'' > 0$, and increases with $x$ if $n'' < 0$. From the argument, the wave is right-moving if $n' >0$, and left-moving if $n' < 0$. Hence, the wave is damped if $n' n'' >0$ and amplified if $n' n'' < 0$.</p><p>(For example, consider the case $n' < 0$ and $n'' < 0$. The amplitude increases with $x$ but the wave is moving in the $-x$ direction; this means the amplitude grows in the direction opposite to the propagation direction, so the wave is damped.)</p><p>For the lower choice of sign, we see from the magnitdue that the amplitude increases with $x$ if $n'' > 0$, and decreases with $x$ if $n'' < 0$. From the argument, we see that the wave is left-moving if $n' >0$ and right-moving if $n' < 0$. Hence, the wave is damped if $n' n'' >0$ and amplified if $n' n'' < 0$, exactly the same as in the previous case.</p><p>Hence, whether the wave is amplified or damped only depends on the relative signs of $n'$ and $n''$, and is independent of the direction of propagation.</p>  \n",
    "</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Complex Derivatives\n",
    "\n",
    "<ol>\n",
    "<li value=\"3\"><a name=\"06_03\"></a>\n",
    "We will use the Cauchy-Riemann equations.  Decompose $z$, $f$, and $g$ into real and imaginary parts as follows: $z = x + i y$, $f = u + i v$, and $g = p + i q$.  Since $f(z)$ and $g(z)$ are analytic in $D$, they satisfy $$\\begin{align} \\frac{\\partial u}{\\partial x} &= \\frac{\\partial v}{\\partial y},\\;\\; -\\frac{\\partial u}{\\partial y} = \\frac{\\partial v}{\\partial x}\\\\ \\frac{\\partial p}{\\partial x} &= \\frac{\\partial q}{\\partial y},\\;\\; -\\frac{\\partial p}{\\partial y} = \\frac{\\partial q}{\\partial x}.\\end{align}$$  This holds for all $z \\in D$. Next, expand the product $f(z)\\,g(z)$ into real and imaginary parts: $$\\begin{align} f(z)\\,g(z) = A(x,y) + i B(x,y),\\;\\;\\mathrm{where}\\;\\; \\begin{cases}A = up - v q \\\\ B = uq + vp. \\end{cases} \\end{align}$$ Our goal is to prove that $A$ and $B$ satisfy the Cauchy-Riemann equations for $x + i y \\in D$, which would then imply that $fg$ is analytic in $D$.  Using the product rule for derivatives: $$\\begin{align} \\frac{\\partial A}{\\partial x} &= \\frac{\\partial u}{\\partial x} p + u \\frac{\\partial p}{\\partial x} - \\frac{\\partial v}{\\partial x} q - v \\frac{\\partial q}{\\partial x} \\\\ &= \\frac{\\partial v}{\\partial y} p + u \\frac{\\partial q}{\\partial y} + \\frac{\\partial u}{\\partial y} q + v \\frac{\\partial p}{\\partial y} \\\\ \\frac{\\partial B}{\\partial y} &= \\frac{\\partial u}{\\partial y} q + u \\frac{\\partial q}{\\partial y} + \\frac{\\partial v}{\\partial y} p + v \\frac{\\partial p}{\\partial y}. \\end{align}$$ By direct comparison, we see that the two expressions are equal. Similarly, $$\\begin{align} \\frac{\\partial A}{\\partial y} &= \\frac{\\partial u}{\\partial y} p + u \\frac{\\partial p}{\\partial y} - \\frac{\\partial v}{\\partial y} q - v \\frac{\\partial q}{\\partial y} \\\\  &= - \\frac{\\partial v}{\\partial x} p - u \\frac{\\partial q}{\\partial x} - \\frac{\\partial u}{\\partial x} q - v \\frac{\\partial p}{\\partial x} \\\\ \\frac{\\partial B}{\\partial x} &=\n",
    "  \\frac{\\partial u}{\\partial x} q + u \\frac{\\partial q}{\\partial x} + \\frac{\\partial v}{\\partial x} p + v \\frac{\\partial p}{\\partial x}.\\end{align}$$ These two are the negatives of each other. Q.E.D.    \n",
    "</li>\n",
    "</ol>\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
